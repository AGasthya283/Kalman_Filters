{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f47ee0c",
   "metadata": {},
   "source": [
    "# 01 — Linear and Extended Kalman Filters\n",
    "\n",
    "> **Level:** Advanced undergraduate / beginning postgraduate\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a4b03b",
   "metadata": {},
   "source": [
    "## Motivation & Intuition\n",
    "\n",
    "Kalman Filters provide a recursive algorithm for estimating the hidden state of a (discrete-time) dynamical system when both the **process** and **measurement** noise are Gaussian. Conceptually the filter alternates between two steps:\n",
    "\n",
    "1. **Predict** — propagate the state distribution through the process model (uncertainty typically increases).\n",
    "2. **Update** — incorporate a measurement to correct the prior belief (uncertainty typically decreases).\n",
    "\n",
    "The filter maintains a Gaussian belief $ \\mathcal{N}(\\hat{x}, P) $. The predict step transforms the mean and covariance under linear dynamics; the update step computes the posterior after incorporating the likelihood.\n",
    "\n",
    "We will derive the key equations, implement a readable KF, visualize interactive behavior with `ipywidgets`, and then extend to the Extended Kalman Filter (EKF) for nonlinear models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12ff390",
   "metadata": {},
   "source": [
    "## Notation and state-space model\n",
    "\n",
    "We use the discrete-time linear state-space model:\n",
    "\n",
    "$$\n",
    "x_k = F_k x_{k-1} + B_k u_k + w_k, \\qquad w_k \\sim \\mathcal{N}(0, Q_k)\n",
    "$$\n",
    "\n",
    "$$\n",
    "z_k = H_k x_k + v_k, \\qquad v_k \\sim \\mathcal{N}(0, R_k)\n",
    "$$\n",
    "\n",
    "- $ x_k $: state vector at time $ k $  \n",
    "- $ u_k $: control input at time $ k $  \n",
    "- $ z_k $: measurement vector at time $ k $\n",
    "- $ F_k, B_k, H_k $: system matrices  \n",
    "- $ Q_k, R_k $ process and measurement covariance matrices\n",
    "\n",
    "Initial belief: $ x_0 \\sim \\mathcal{N}(\\hat{x}_0, P_0) $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d14cbf8",
   "metadata": {},
   "source": [
    "## Bayesian sketch\n",
    "\n",
    "From Bayes' theorem:\n",
    "\n",
    "$$\n",
    "p(x_k | z_{1:k}) \\propto p(z_k | x_k) \\, p(x_k | z_{1:k-1}).\n",
    "$$\n",
    "\n",
    "Under linear-Gaussian assumptions the prior and likelihood are Gaussians; multiplying two Gaussians yields a Gaussian and closed-form expressions for the posterior mean and covariance. The resulting recursive equations are the Kalman Filter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6e1992",
   "metadata": {},
   "source": [
    "## Predict–Update equations \n",
    "\n",
    "**Prediction**\n",
    "\n",
    "$$\n",
    "\\hat{x}_{k|k-1} = F_k \\hat{x}_{k-1|k-1} + B_k u_k\n",
    "$$\n",
    "\n",
    "$$\n",
    "P_{k|k-1} = F_k P_{k-1|k-1} F_k^T + Q_k\n",
    "$$\n",
    "\n",
    "**Kalman gain**\n",
    "\n",
    "$$\n",
    "K_k = P_{k|k-1} H_k^T (H_k P_{k|k-1} H_k^T + R_k)^{-1}\n",
    "$$\n",
    "\n",
    "**Update**\n",
    "\n",
    "$$\n",
    "\\hat{x}_{k|k} = \\hat{x}_{k|k-1} + K_k (z_k - H_k \\hat{x}_{k|k-1})\n",
    "$$\n",
    "\n",
    "$$\n",
    "P_{k|k} = (I - K_k H_k) P_{k|k-1} (I - K_k H_k)^T + K_k R_k K_k^T\n",
    "$$\n",
    "\n",
    "(Use the Joseph form above for better numerical stability; the simplified form $ P = (I-KH)P $ is sometimes used.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1fae5c",
   "metadata": {},
   "source": [
    "### Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d406ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, FloatSlider, IntSlider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc7252b",
   "metadata": {},
   "source": [
    "## Implementation of `LinearKalmanFilter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63e09dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearKalmanFilter:\n",
    "    \"\"\"\n",
    "    Minimal, readable Linear Kalman Filter implementation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    F, H, Q, R : array-like\n",
    "        System matrices.\n",
    "    x0 : array-like\n",
    "        Initial state estimate.\n",
    "    P0 : array-like\n",
    "        Initial covariance.\n",
    "    B : array-like, optional\n",
    "        Control matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, F, H, Q, R, x0, P0, B=None):\n",
    "        self.F = np.atleast_2d(np.array(F, dtype=float))\n",
    "        self.H = np.atleast_2d(np.array(H, dtype=float))\n",
    "        self.Q = np.atleast_2d(np.array(Q, dtype=float))\n",
    "        self.R = np.atleast_2d(np.array(R, dtype=float))\n",
    "        self.x = np.atleast_1d(np.array(x0, dtype=float))\n",
    "        self.P = np.atleast_2d(np.array(P0, dtype=float))\n",
    "        self.B = None if B is None else np.atleast_2d(np.array(B, dtype=float))\n",
    "\n",
    "    def predict(self, u=None):\n",
    "        \"\"\"Predict step: propagate mean and covariance.\n",
    "\n",
    "        x_{k|k-1} = F x_{k-1|k-1} + B u\n",
    "        P_{k|k-1} = F P_{k-1|k-1} F^T + Q\n",
    "        \"\"\"\n",
    "        if (self.B is not None) and (u is not None):\n",
    "            self.x = self.F @ self.x + self.B @ np.atleast_1d(u)\n",
    "        else:\n",
    "            self.x = self.F @ self.x\n",
    "        self.P = self.F @ self.P @ self.F.T + self.Q\n",
    "        return self.x, self.P\n",
    "\n",
    "    def update(self, z):\n",
    "        \"\"\"Update step using measurement z.\n",
    "\n",
    "        K = P H^T (H P H^T + R)^{-1}\n",
    "        x = x + K (z - H x)\n",
    "        P = (I - K H) P (I - K H)^T + K R K^T  # Joseph form\n",
    "        \"\"\"\n",
    "        z = np.atleast_1d(z)\n",
    "        S = self.H @ self.P @ self.H.T + self.R\n",
    "        K = self.P @ self.H.T @ inv(S)\n",
    "        y = z - (self.H @ self.x)\n",
    "        self.x = self.x + K @ y\n",
    "        I = np.eye(self.P.shape[0])\n",
    "        self.P = (I - K @ self.H) @ self.P @ (I - K @ self.H).T + K @ self.R @ K.T\n",
    "        return self.x, self.P, K\n",
    "\n",
    "    def step(self, z=None, u=None):\n",
    "        \"\"\"Convenience: predict then optionally update.\"\"\"\n",
    "        self.predict(u=u)\n",
    "        if z is None:\n",
    "            return self.x, self.P\n",
    "        return self.update(z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df278393",
   "metadata": {},
   "source": [
    "### Explanation of the `LinearKalmanFilter` code\n",
    "\n",
    "- `predict`: computes the prior mean and covariance. If a control input `u` and matrix `B` are provided, it includes the control effect.\n",
    "- `update`: computes the innovation covariance `S`, the Kalman gain `K`, the innovation `y`, then updates the state and covariance. The Joseph form preserves symmetry and is numerically more robust.\n",
    "- `step`: a convenience wrapper for predict + optional update.\n",
    "\n",
    "**Implementation notes**\n",
    "- Avoid explicit matrix inverse `inv(S)` in performance-critical or large systems — prefer `np.linalg.solve(S, ...)` or Cholesky-based solvers from `scipy.linalg`.\n",
    "- Check/force symmetry of `P` occasionally: `P = 0.5*(P + P.T)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb6fd43",
   "metadata": {},
   "source": [
    "## Interactive demo — 1D constant-velocity tracking\n",
    "\n",
    "This demo simulates a 1D constant-velocity model (state `[position, velocity]`) and noisy position measurements.\n",
    "\n",
    "Controls:\n",
    "- `Q_scale`: scales baseline process noise\n",
    "- `R`: measurement variance\n",
    "\n",
    "Plots show true trajectory, noisy measurements, KF estimate, and 95% confidence bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f4d339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf1fb4fe77a41a19aafd04b64b6f176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.01, description='Q scale', max=0.1, min=0.0001, step=0.0001), FloatS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Simulation helper\n",
    "def simulate_constant_velocity(T=50, dt=1.0, x0=np.array([0.0, 1.0]), Q=None, R=1.0):\n",
    "    F = np.array([[1, dt],[0,1]])\n",
    "    H = np.array([[1, 0]])\n",
    "    if Q is None:\n",
    "        Q = np.diag([1e-2, 1e-3])\n",
    "    x = x0.copy().astype(float)\n",
    "    xs = []\n",
    "    zs = []\n",
    "    for k in range(T):\n",
    "        w = np.random.multivariate_normal(np.zeros(2), Q)\n",
    "        x = F @ x + w\n",
    "        v = np.random.normal(0, np.sqrt(R))\n",
    "        z = float(H @ x + v)\n",
    "        xs.append(x.copy())\n",
    "        zs.append(z)\n",
    "    return np.array(xs), np.array(zs), F, H, Q, R\n",
    "\n",
    "# Demo runner\n",
    "def run_demo(Q_scale=1e-2, R=1.0, T=80):\n",
    "    np.random.seed(1)\n",
    "    xs, zs, F, H, Q_true, R_true = simulate_constant_velocity(T=T, Q=np.diag([Q_scale, Q_scale*0.5]), R=R)\n",
    "\n",
    "    x0 = np.array([0.0, 0.0])\n",
    "    P0 = np.diag([1.0, 1.0])\n",
    "    kf = LinearKalmanFilter(F=F, H=H, Q=Q_true, R=np.atleast_2d(R_true), x0=x0, P0=P0)\n",
    "\n",
    "    ests = []\n",
    "    Ps = []\n",
    "    for z in zs:\n",
    "        kf.predict()\n",
    "        kf.update(z)\n",
    "        ests.append(kf.x.copy())\n",
    "        Ps.append(kf.P.copy())\n",
    "    ests = np.array(ests)\n",
    "    Ps = np.array(Ps)\n",
    "\n",
    "    t = np.arange(len(zs))\n",
    "    fig, ax = plt.subplots(2,1, figsize=(10,6), sharex=True)\n",
    "    ax[0].plot(t, xs[:,0], '-k', label='true position')\n",
    "    ax[0].scatter(t, zs, s=10, label='measurements')\n",
    "    ax[0].plot(t, ests[:,0], '-r', label='KF estimate')\n",
    "    ax[0].fill_between(t, ests[:,0] - 2*np.sqrt(Ps[:,0,0]), ests[:,0] + 2*np.sqrt(Ps[:,0,0]), alpha=0.2)\n",
    "    ax[0].legend(); ax[0].set_ylabel('position')\n",
    "\n",
    "    ax[1].plot(t, xs[:,1], '-k', label='true velocity')\n",
    "    ax[1].plot(t, ests[:,1], '-r', label='KF estimate')\n",
    "    ax[1].fill_between(t, ests[:,1] - 2*np.sqrt(Ps[:,1,1]), ests[:,1] + 2*np.sqrt(Ps[:,1,1]), alpha=0.2)\n",
    "    ax[1].legend(); ax[1].set_ylabel('velocity'); ax[1].set_xlabel('time step')\n",
    "    plt.show()\n",
    "\n",
    "# In a Jupyter notebook run the interact cell\n",
    "interact(run_demo,\n",
    "         Q_scale=FloatSlider(min=1e-4, max=1e-1, step=1e-4, value=1e-2, description='Q scale'),\n",
    "         R=FloatSlider(min=1e-3, max=10.0, step=1e-3, value=1.0, description='R'),\n",
    "         T=IntSlider(min=20, max=200, step=10, value=80));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd78c296",
   "metadata": {},
   "source": [
    "### Explanation of the interactive demo\n",
    "\n",
    "- `simulate_constant_velocity` builds ground-truth states and noisy position measurements.\n",
    "- In `run_demo`, we initialize a `LinearKalmanFilter` and run predict/update for each measurement.\n",
    "- The 95% bands come from ±2 standard deviations from the respective diagonal of `P`.\n",
    "- Change `Q_scale` and `R` to see filter sensitivity:\n",
    "  - Larger `R`: measurements are noisy → filter trusts model more, bands widen.\n",
    "  - Larger `Q`: process uncertainty grows → filter tracks measurements more closely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a14865",
   "metadata": {},
   "source": [
    "## Extended Kalman Filter (EKF)\n",
    "\n",
    "For nonlinear dynamics:\n",
    "\n",
    "$$\n",
    "x_k = f(x_{k-1}, u_k) + w_k, \\qquad w_k \\sim \\mathcal{N}(0,Q_k)\n",
    "$$\n",
    "\n",
    "$$\n",
    "z_k = h(x_k) + v_k, \\qquad v_k \\sim \\mathcal{N}(0,R_k)\n",
    "$$\n",
    "\n",
    "Linearize `f` and `h` around current estimate:\n",
    "\n",
    "$$\n",
    "F_k = \\left.\\frac{\\partial f}{\\partial x}\\right|_{\\hat{x}_{k-1|k-1}}, \\qquad\n",
    "H_k = \\left.\\frac{\\partial h}{\\partial x}\\right|_{\\hat{x}_{k|k-1}}.\n",
    "$$\n",
    "\n",
    "Then apply the KF predict/update using these time-varying Jacobians.\n",
    "\n",
    "**Algorithm**\n",
    "1. Predict: $ \\hat{x}_{k|k-1} = f(\\hat{x}_{k-1|k-1}, u_k) $, $ P_{k|k-1} = F_k P_{k-1|k-1} F_k^T + Q_k $.\n",
    "2. Update: compute Kalman gain with $ H_k $, form innovation $ z_k - h(\\hat{x}_{k|k-1}) $, update mean and covariance.\n",
    "\n",
    "**Warning:** EKF can diverge if linearization is poor; use UKF or particle filters for highly nonlinear / multimodal problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9e2193",
   "metadata": {},
   "source": [
    "## Implementation of `ExtendedKalmanFilter`\n",
    "\n",
    "The inputs used below can be defined as:\n",
    "- `f(x, u)` (state transition function)\n",
    "- `h(x)` (measurement function)\n",
    "- `F_jac(x, u)` (Jacobian of `f` wrt `x`)\n",
    "- `H_jac(x)` (Jacobian of `h` wrt `x`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c03c8f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtendedKalmanFilter:\n",
    "    \"\"\"\n",
    "    Simple Extended Kalman Filter implementation.\n",
    "\n",
    "    User must provide:\n",
    "      - f(x, u): state transition function\n",
    "      - h(x): measurement function\n",
    "      - F_jac(x, u): Jacobian of f wrt x (evaluated at previous/predicted state)\n",
    "      - H_jac(x): Jacobian of h wrt x (evaluated at predicted state)\n",
    "    \"\"\"\n",
    "    def __init__(self, f, h, F_jac, H_jac, Q, R, x0, P0):\n",
    "        self.f = f\n",
    "        self.h = h\n",
    "        self.F_jac = F_jac\n",
    "        self.H_jac = H_jac\n",
    "        self.Q = np.atleast_2d(np.array(Q, dtype=float))\n",
    "        self.R = np.atleast_2d(np.array(R, dtype=float))\n",
    "        self.x = np.atleast_1d(np.array(x0, dtype=float))\n",
    "        self.P = np.atleast_2d(np.array(P0, dtype=float))\n",
    "\n",
    "    def predict(self, u=None):\n",
    "        # propagate mean\n",
    "        self.x = self.f(self.x, u) if u is not None else self.f(self.x, None)\n",
    "        # compute jacobian and propagate covariance\n",
    "        F = self.F_jac(self.x, u)\n",
    "        self.P = F @ self.P @ F.T + self.Q\n",
    "        return self.x, self.P\n",
    "\n",
    "    def update(self, z):\n",
    "        H = self.H_jac(self.x)\n",
    "        S = H @ self.P @ H.T + self.R\n",
    "        K = self.P @ H.T @ inv(S)\n",
    "        y = z - self.h(self.x)\n",
    "        # If measurements include angles, normalize angle components of y to [-pi, pi]\n",
    "        self.x = self.x + K @ y\n",
    "        I = np.eye(self.P.shape[0])\n",
    "        self.P = (I - K @ H) @ self.P @ (I - K @ H).T + K @ self.R @ K.T\n",
    "        return self.x, self.P, K\n",
    "\n",
    "    def step(self, z=None, u=None):\n",
    "        self.predict(u=u)\n",
    "        if z is not None:\n",
    "            return self.update(z)\n",
    "        return self.x, self.P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6b0530",
   "metadata": {},
   "source": [
    "### Explanation of the EKF implementation\n",
    "\n",
    "- `predict`: uses `f` to propagate the mean and `F_jac` (Jacobian) to propagate covariance.\n",
    "- `update`: linearizes observation function at the predicted mean (`H_jac`), computes Kalman gain and innovation `y = z - h(x_pred)`, then updates the mean and covariance using Joseph form.\n",
    "- Remember to normalize angular residuals in `y` when using bearings (wrap to $ [-\\pi,\\pi] $).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f589cdd",
   "metadata": {},
   "source": [
    "## Interactive demo with a Nonlinear example — Bearing-range tracking (EKF)\n",
    "\n",
    "We track a target in 2D:\n",
    "\n",
    "State: $ x = [p_x, p_y, v_x, v_y]^T $ \n",
    "Sensor at origin measures bearing and range:\n",
    "\n",
    "$$\n",
    "z = \\begin{bmatrix} \\operatorname{atan2}(p_y, p_x) \\\\ \\sqrt{p_x^2 + p_y^2} \\end{bmatrix} + v\n",
    "$$\n",
    "\n",
    "Motion model: constant velocity.\n",
    "\n",
    "We'll simulate the true trajectory with process noise, generate noisy bearing+range measurements, then run the EKF and plot true path vs estimate.\n",
    "\n",
    "This interactive demo simulates a 2D target moving with **constant velocity** and a sensor at the origin providing **bearing + range** measurements (noisy).  \n",
    "\n",
    "Controls:\n",
    "- **Q scale**: multiplies a baseline process-noise covariance (increases process uncertainty / model noise).  \n",
    "- **Bearing noise (deg)**: standard deviation of bearing measurement noise in degrees.  \n",
    "- **Range noise (m)**: standard deviation of range measurement noise in meters.  \n",
    "- **T**: number of time steps to simulate.\n",
    "\n",
    "What the demo does:\n",
    "1. Simulates the true trajectory with process noise.\n",
    "2. Creates noisy bearing+range measurements.\n",
    "3. Runs the EKF using the supplied `f`, `h`, `F_jac`, `H_jac` (same functions as earlier).\n",
    "4. Plots: true trajectory (black), EKF estimate (red), measurement-inferred Cartesian points (blue crosses), and the sensor at the origin (green X).  \n",
    "5. Angle residuals are normalized to $ [-\\pi, \\pi] $ before update.\n",
    "\n",
    "Use this to explore how EKF behaves with different noise levels and to observe failure modes (angle wrapping / singularities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb5116f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9010ce9897444faaa481fccc8ccb6bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.0, description='Q scale', max=10.0), FloatSlider(value=1.0, descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- helper: angle normalization ---\n",
    "def angle_wrap(a):\n",
    "    \"\"\"Wrap angle(s) to [-pi, pi].\"\"\"\n",
    "    return (a + np.pi) % (2*np.pi) - np.pi\n",
    "\n",
    "# --- motion & measurement functions (same as notebook) ---\n",
    "def f_cv(x, u=None, dt=1.0):\n",
    "    F = np.array([[1,0,dt,0],\n",
    "                  [0,1,0,dt],\n",
    "                  [0,0,1,0],\n",
    "                  [0,0,0,1]])\n",
    "    return F @ x\n",
    "\n",
    "def h_bearing_range(x):\n",
    "    px, py, vx, vy = x\n",
    "    rng = np.hypot(px, py)\n",
    "    bearing = np.arctan2(py, px)\n",
    "    return np.array([bearing, rng])\n",
    "\n",
    "F_jac = lambda x, u=None: np.array([[1,0,1,0],[0,1,0,1],[0,0,1,0],[0,0,0,1]])\n",
    "\n",
    "def H_jac(x):\n",
    "    px, py, vx, vy = x\n",
    "    rng = np.hypot(px, py)\n",
    "    if rng < 1e-8:\n",
    "        return np.zeros((2,4))\n",
    "    H = np.zeros((2,4))\n",
    "    H[0,0] = -py / (rng**2)\n",
    "    H[0,1] = px / (rng**2)\n",
    "    H[1,0] = px / rng\n",
    "    H[1,1] = py / rng\n",
    "    return H\n",
    "\n",
    "# --- EKF class (lightweight, uses solve for K computation) ---\n",
    "class ExtendedKalmanFilterSimple:\n",
    "    def __init__(self, f, h, F_jac, H_jac, Q, R, x0, P0):\n",
    "        self.f = f\n",
    "        self.h = h\n",
    "        self.F_jac = F_jac\n",
    "        self.H_jac = H_jac\n",
    "        self.Q = np.atleast_2d(np.array(Q, dtype=float))\n",
    "        self.R = np.atleast_2d(np.array(R, dtype=float))\n",
    "        self.x = np.atleast_1d(np.array(x0, dtype=float))\n",
    "        self.P = np.atleast_2d(np.array(P0, dtype=float))\n",
    "\n",
    "    def predict(self, u=None):\n",
    "        self.x = self.f(self.x, u) if u is not None else self.f(self.x, None)\n",
    "        F = self.F_jac(self.x, u)\n",
    "        self.P = F @ self.P @ F.T + self.Q\n",
    "        return self.x, self.P\n",
    "\n",
    "    def update(self, z):\n",
    "        H = self.H_jac(self.x)\n",
    "        S = H @ self.P @ H.T + self.R\n",
    "        # Solve for K without explicit inverse: K = P H^T S^{-1}\n",
    "        # compute K by solving S^T y = (P H^T)^T for y, then transpose back\n",
    "        PHt = self.P @ H.T\n",
    "        K = np.linalg.solve(S.T, PHt.T).T\n",
    "        y = z - self.h(self.x)\n",
    "        # angle normalization (first component is bearing)\n",
    "        if y.shape[0] >= 1:\n",
    "            y[0] = angle_wrap(y[0])\n",
    "        self.x = self.x + K @ y\n",
    "        I = np.eye(self.P.shape[0])\n",
    "        self.P = (I - K @ H) @ self.P @ (I - K @ H).T + K @ self.R @ K.T\n",
    "        return self.x, self.P, K\n",
    "\n",
    "    def step(self, z=None, u=None):\n",
    "        self.predict(u=u)\n",
    "        if z is not None:\n",
    "            return self.update(z)\n",
    "        return self.x, self.P\n",
    "\n",
    "# --- helper to draw measurement positions from (bearing,range) ---\n",
    "def meas_to_cart(bearing, rng):\n",
    "    return rng * np.array([np.cos(bearing), np.sin(bearing)])\n",
    "\n",
    "# --- interactive runner ---\n",
    "def run_ekf_demo(Q_scale=1.0, bearing_noise_deg=1.0, range_noise=0.5, T=80, seed=2):\n",
    "    np.random.seed(seed)\n",
    "    # Baseline true params\n",
    "    x_true0 = np.array([5.0, 0.0, 0.5, 0.2])\n",
    "    Q_base = np.diag([1e-3, 1e-3, 1e-4, 1e-4])\n",
    "    Q = Q_scale * Q_base\n",
    "    R = np.diag([np.deg2rad(bearing_noise_deg)**2, range_noise**2])\n",
    "\n",
    "    # simulate true trajectory and measurements\n",
    "    xs = []\n",
    "    zs = []\n",
    "    x_true = x_true0.copy()\n",
    "    for k in range(T):\n",
    "        x_true = f_cv(x_true)\n",
    "        x_true = x_true + np.random.multivariate_normal(np.zeros(4), Q)\n",
    "        z = h_bearing_range(x_true) + np.random.multivariate_normal(np.zeros(2), R)\n",
    "        zs.append(z.copy())\n",
    "        xs.append(x_true.copy())\n",
    "    xs = np.array(xs)\n",
    "    zs = np.array(zs)\n",
    "\n",
    "    # instantiate EKF\n",
    "    x0 = np.array([4.0, -1.0, 0.0, 0.0])\n",
    "    P0 = np.diag([1.0, 1.0, 0.5, 0.5])\n",
    "    ekf = ExtendedKalmanFilterSimple(f=f_cv, h=h_bearing_range, F_jac=F_jac, H_jac=H_jac, Q=Q, R=R, x0=x0, P0=P0)\n",
    "\n",
    "    ests = []\n",
    "    Ps = []\n",
    "    meas_cart = []\n",
    "    for z in zs:\n",
    "        ekf.predict()\n",
    "        ekf.update(z)\n",
    "        ests.append(ekf.x.copy())\n",
    "        Ps.append(ekf.P.copy())\n",
    "        meas_cart.append(meas_to_cart(z[0], z[1]))\n",
    "    ests = np.array(ests)\n",
    "    Ps = np.array(Ps)\n",
    "    meas_cart = np.array(meas_cart)\n",
    "\n",
    "    # Plot results\n",
    "    fig, ax = plt.subplots(1,1, figsize=(8,6))\n",
    "    ax.plot(xs[:,0], xs[:,1], '-k', lw=1.5, label='true')\n",
    "    ax.plot(ests[:,0], ests[:,1], '-r', lw=1.5, label='EKF estimate')\n",
    "    ax.scatter(meas_cart[:,0], meas_cart[:,1], marker='x', c='tab:blue', label='measurements (cartesian)')\n",
    "    ax.scatter([0], [0], marker='x', c='g', s=80, label='sensor (origin)')\n",
    "    ax.legend(loc='best')\n",
    "    ax.set_xlabel('x [m]'); ax.set_ylabel('y [m]'); ax.set_title('Bearing-range tracking (interactive EKF)')\n",
    "    ax.axis('equal')\n",
    "    ax.grid(True)\n",
    "\n",
    "    # optional: draw covariance ellipse for selected times (e.g., last state)\n",
    "    try:\n",
    "        cov = Ps[-1][:2,:2]  # position sub-covariance\n",
    "        vals, vecs = np.linalg.eigh(cov)\n",
    "        order = vals.argsort()[::-1]\n",
    "        vals = vals[order]\n",
    "        vecs = vecs[:,order]\n",
    "        angle = np.degrees(np.arctan2(vecs[1,0], vecs[0,0]))\n",
    "        width, height = 2*2*np.sqrt(vals)  # 2-sigma ellipse\n",
    "        ell = Ellipse(xy=(ests[-1,0], ests[-1,1]), width=width, height=height,\n",
    "                      angle=angle, edgecolor='r', facecolor='none', linestyle='--', linewidth=1.2, label='2-sigma pos')\n",
    "        ax.add_patch(ell)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# interactive widget controls\n",
    "interact(run_ekf_demo,\n",
    "         Q_scale=FloatSlider(value=1.0, min=0.0, max=10.0, step=0.1, description='Q scale'),\n",
    "         bearing_noise_deg=FloatSlider(value=1.0, min=0.01, max=10.0, step=0.1, description='bearing σ (deg)'),\n",
    "         range_noise=FloatSlider(value=0.5, min=0.01, max=5.0, step=0.01, description='range σ (m)'),\n",
    "         T=IntSlider(value=80, min=10, max=300, step=10, description='T'),\n",
    "         seed=IntSlider(value=2, min=0, max=50, step=1, description='seed'));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae1b348",
   "metadata": {},
   "source": [
    "### Explanation and caveats for the bearing-range example\n",
    "\n",
    "- Bearing is an angular measurement; **always** normalize the angle residual to $ [-\\pi, \\pi] $ before updating.\n",
    "- Near sensor singularities (range → 0) the Jacobian becomes ill-conditioned; handle these cases explicitly (fallback, skip update, or use alternate sensor combination).\n",
    "- EKF uses local linearization — if the posterior uncertainty is large or the system is highly nonlinear, EKF may diverge. UKF or particle filters are alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08085f10",
   "metadata": {},
   "source": [
    "## Practical tips, exercises & references\n",
    "\n",
    "**Practical tips**\n",
    "- Use the Joseph form for covariance updates to preserve positive semi-definiteness.\n",
    "- Avoid explicit inverses — prefer solvers (`np.linalg.solve`) or Cholesky (`scipy.linalg.cho_factor` / `cho_solve`).\n",
    "- Tune `Q` and `R` carefully — they determine filter responsiveness and stability.\n",
    "- Normalize angle residuals for bearings; symmetrize `P` occasionally.\n",
    "\n",
    "**Exercises**\n",
    "1. Implement an Unscented Kalman Filter (UKF) and compare with EKF on the bearing-range example.\n",
    "2. Implement a square-root Kalman filter and analyze numerical stability.\n",
    "3. Replace the CV model with a coordinated-turn model and evaluate EKF vs UKF.\n",
    "4. Fuse IMU + GPS using an EKF and analyze estimate consistency.\n",
    "\n",
    "**References (cite when quoting)**\n",
    "- R. E. Kalman, \"A New Approach to Linear Filtering and Prediction Problems\", *Transactions of the ASME — Journal of Basic Engineering*, 1960.\n",
    "- G. Welch & G. Bishop, \"An Introduction to the Kalman Filter\", UNC Chapel Hill, 1995. (tutorial)\n",
    "- S. J. Julier & J. K. Uhlmann, \"A New Extension of the Kalman Filter to Nonlinear Systems\", *Proceedings of SPIE*, 1997. (UKF foundational paper)\n",
    "- D. Simon, *Optimal State Estimation: Kalman, H Infinity, and Nonlinear Approaches*, Wiley, 2006.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
